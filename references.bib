@article{arik2018fast,
	title = {Fast spectrogram inversion using multi-head convolutional neural networks},
	author = {Ar{\i}k, Sercan {\"O} and Jun, Heewoo and Diamos, Gregory},
	year = 2018,
	journal = {IEEE Signal Processing Letters},
	publisher = {IEEE},
	volume = 26,
	number = 1,
	pages = {94--98}
}
@article{barahona2023noisebandnet,
	title = {NoiseBandNet: Controllable Time-Varying Neural Synthesis of Sound Effects Using Filterbanks},
	author = {Barahona-R{\'\i}os, Adri{\'a}n and Collins, Tom},
	year = 2023,
	journal = {arXiv preprint arXiv:2307.08007}
}
@inproceedings{cherep2023synthax,
title = {SynthAX: A Fast Modular Synthesizer in JAX},
author = {Cherep, Manuel and Singh, Nikhil},
booktitle = {Audio Engineering Society Convention 155},
month = {May},
year = {2023},
url = {http://www.aes.org/e-lib/browse.cfm?elib=22261}
}
@inproceedings{diaz_rigid-body_2022,
  title={Rigid-Body Sound Synthesis with Differentiable Modal Resonators},
  author={Diaz, Rodrigo and Hayes, Ben and Saitis, Charalampos and Fazekas, Gy{\"o}rgy and Sandler, Mark},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2023},
  organization={IEEE}
}
@inproceedings{engel_ddsp_2020,
	title = {{{DDSP}}: {{Differentiable Digital Signal Processing}}},
	shorttitle = {{{DDSP}}},
	author = {Engel, Jesse and Hantrakul, Lamtharn (Hanoi) and Gu, Chenjie and Roberts, Adam},
	year = 2020,
	month = apr,
	booktitle = {8th {{International Conference}} on {{Learning Representations}}},
	urldate = {2020-01-29}
}
@inproceedings{engel2017neural,
	title = {Neural audio synthesis of musical notes with wavenet autoencoders},
	author = {Engel, Jesse and Resnick, Cinjon and Roberts, Adam and Dieleman, Sander and Norouzi, Mohammad and Eck, Douglas and Simonyan, Karen},
	year = 2017,
	booktitle = {International Conference on Machine Learning},
	pages = {1068--1077},
	organization = {PMLR}
}
@inproceedings{hayes2023sinusoidal,
	title = {Sinusoidal Frequency Estimation by Gradient Descent},
	author = {Hayes, Ben and Saitis, Charalampos and Fazekas, Gy{\"o}rgy},
	year = 2023,
	booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages = {1--5},
	organization = {IEEE}
}
@inproceedings{kim2018crepe,
	title = {Crepe: A convolutional representation for pitch estimation},
	author = {Kim, Jong Wook and Salamon, Justin and Li, Peter and Bello, Juan Pablo},
	year = 2018,
	booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages = {161--165},
	organization = {IEEE}
}
@article{liu2023ddsp,
	title = {DDSP-SFX: Acoustically-guided sound effects generation with differentiable digital signal processing},
	author = {Liu, Yunyi and Jin, Craig and Gunawan, David},
	year = 2023,
	journal = {arXiv preprint arXiv:2309.08060}
}
@article{masuda_improving_2023,
	title = {Improving {{Semi-Supervised Differentiable Synthesizer Sound Matching}} for {{Practical Applications}}},
	author = {Masuda, Naotake and Saito, Daisuke},
	year = 2023,
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	volume = 31,
	pages = {863--875},
	doi = {10.1109/TASLP.2023.3237161},
	issn = {2329-9304}
}
@inproceedings{renault_differentiable_2022,
	title = {Differentiable {{Piano Model}} for {{Midi-to-Audio Performance Synthesis}}},
	author = {Renault, Lenny and Mignot, R{\'e}mi and Roebel, Axel},
	year = 2022,
	booktitle = {Proceedings of the 25th {{International Conference}} on {{Digital Audio Effects}}},
	address = {{Vienna, Austria}},
	pages = 8
}
@article{serra_spectral_1990,
	title = {Spectral {{Modeling Synthesis}}: {{A Sound Analysis}}/{{Synthesis System Based}} on a {{Deterministic Plus Stochastic Decomposition}}},
	shorttitle = {Spectral {{Modeling Synthesis}}},
	author = {Serra, Xavier and Smith, Julius},
	year = 1990,
	journal = {Computer Music Journal},
	volume = 14,
	number = 4,
	pages = {12--24},
	doi = {10.2307/3680788},
	issn = {0148-9267},
	url = {www.jstor.org/stable/3680788},
	urldate = {2019-12-21}
}
@inproceedings{shier2023differentiable,
	title = {Differentiable Modelling of Percussive Audio with Transient and Spectral Synthesis},
	author = {Shier, Jordie and Caspe, Franco and Robertson, Andrew and Sandler, Mark and Saitis, Charalampos and McPherson, Andrew},
	year = 2023,
	booktitle = {Proceedings of the 10th Convention of the European Acoustics Association Forum Acusticum 2023}
}
@inproceedings{turian_one_2021,
  title = {One {{Billion Audio Sounds}} from {{GPU-enabled Modular Synthesis}}},
  author = {Turian, Joseph and Shier, Jordie and Tzanetakis, George and McNally, Kirk and Henry, Max},
  year = 2021,
  booktitle = {Proceedings of the 23rd International Conference on Digital Audio Effects}
}
@article{wang2019neural,
	title = {Neural source-filter waveform models for statistical parametric speech synthesis},
	author = {Wang, Xin and Takaki, Shinji and Yamagishi, Junichi},
	year = 2019,
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	publisher = {IEEE},
	volume = 28,
	pages = {402--415}
}
@inproceedings{wu_ddsp-based_2022,
	title = {{{DDSP-based Singing Vocoders}}: {{A New Subtractive-based Synthesizer}} and {{A Comprehensive Evaluation}}},
	author = {Wu, Da-Yi and Hsiao, Wen-Yi and Yang, Fu-Rong and Friedman, Oscar and Jackson, Warren and Bruzenak, Scott and Liu, Yi-Wen and Yang, Yi-Hsuan},
	year = 2022,
	booktitle = {Proceedings of the 23rd International Society for Music Information Retrieval Conference},
	pages = {76--83}
}

@book{smith_filters_2007,
	AUTHOR = "Julius O. Smith",
	TITLE = "Introduction to Digital Filters with Audio Applications",
	PUBLISHER = "W3K Publishing",
	ADDRESS = "http://www.w3k.org/books/",
	YEAR = 2007,
	ISBN = "978-0-9745607-1-7"
}

@inproceedings{wang_neural_2019,
  title = {Neural {{Harmonic-plus-Noise Waveform Model}} with {{Trainable Maximum Voice Frequency}} for {{Text-to-Speech Synthesis}}},
  booktitle = {10th {{ISCA Workshop}} on {{Speech Synthesis}} ({{SSW}} 10)},
  author = {Wang, Xin and Yamagishi, Junichi},
  year = {2019},
  month = sep,
  pages = {1--6},
  publisher = {{ISCA}},
  doi = {10.21437/SSW.2019-1},
  urldate = {2023-07-04},
  abstract = {Neural source-filter (NSF) models are deep neural networks that produce waveforms given input acoustic features. They use dilated-convolution-based neural filter modules to filter sinebased excitation for waveform generation, which is different from WaveNet and flow-based models. One of the NSF models, called harmonic-plus-noise NSF (h-NSF) model, uses separate pairs of source and neural filters to generate harmonic and noise waveform components. It is close to WaveNet in terms of speech quality while being superior in generation speed.},
  file = {/Users/benhayes/Zotero/storage/J6NCJG6J/Wang and Yamagishi - 2019 - Neural Harmonic-plus-Noise Waveform Model with Tra.pdf}
}

@ARTICLE{jorda_performance_2019,
  author={Jordà, Marc and Valero-Lara, Pedro and Peña, Antonio J.},
  journal={IEEE Access},
  title={Performance Evaluation of cuDNN Convolution Algorithms on NVIDIA Volta GPUs},
  year={2019},
  volume={7},
  number={},
  pages={70461-70473},
  doi={10.1109/ACCESS.2019.2918851}
}

@misc{barahona-rios_noisebandnet_2023,
  title = {{{NoiseBandNet}}: {{Controllable Time-Varying Neural Synthesis}} of {{Sound Effects Using Filterbanks}}},
  shorttitle = {{{NoiseBandNet}}},
  author = {{Barahona-R{\'i}os}, Adri{\'a}n and Collins, Tom},
  year = {2023},
  month = jul,
  number = {arXiv:2307.08007},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2307.08007},
}

@article{hayes_review_2023,
  title = {A {{Review}} of {{Differentiable Digital Signal Processing}} for {{Music}} \& {{Speech Synthesis}}},
  author = {Hayes, Ben and Shier, Jordie and Fazekas, Gy{\"o}rgy and McPherson, Andrew and Saitis, Charalampos},
  year = {2023},
  month = aug,
  number = {arXiv:2308.15422},
  eprint = {2308.15422},
  primaryclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.15422},
  urldate = {2023-09-05},
}

@inproceedings{oord_wavenet_2016,
title	= {WaveNet: A Generative Model for Raw Audio},
author	= {Aäron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alexander Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
year	= {2016},
URL	= {https://arxiv.org/abs/1609.03499},
booktitle	= {Arxiv}
}

@inproceedings{kong_hifi-gan_2020,
author = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
title = {HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Several recent work on speech synthesis have employed generative adversarial networks (GANs) to produce raw waveforms. Although such methods improve the sampling efficiency and memory usage, their sample quality has not yet reached that of autoregressive and flow-based generative models. In this work, we propose HiFi-GAN, which achieves both efficient and high-fidelity speech synthesis. As speech audio consists of sinusoidal signals with various periods, we demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality. A subjective human evaluation (mean opinion score, MOS) of a single speaker dataset indicates that our proposed method demonstrates similarity to human quality while generating 22.05 kHz high-fidelity audio 167.9 times faster than real-time on a single V100 GPU. We further show the generality of HiFi-GAN to the mel-spectrogram inversion of unseen speakers and end-to-end speech synthesis. Finally, a small footprint version of HiFi-GAN generates samples 13.4 times faster than real-time on CPU with comparable quality to an autoregressive counterpart.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {1428},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}

@inproceedings{juvela_gelp_2019,
  author={Lauri Juvela and Bajibabu Bollepalli and Junichi Yamagishi and Paavo Alku},
  title={{GELP: GAN-Excited Linear Prediction for Speech Synthesis from Mel-Spectrogram}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={694--698},
  doi={10.21437/Interspeech.2019-2008}
}

@inproceedings{engel_self-supervised_2020,
title={Self-supervised Pitch Detection by Inverse Audio Synthesis},
author={Jesse Engel and Rigel Swavely and Lamtharn Hanoi Hantrakul and Adam Roberts and Curtis Hawthorne},
booktitle={ICML 2020 Workshop on Self-supervision in Audio and Speech},
year={2020},
url={https://openreview.net/forum?id=RlVTYWhsky7}
}

@ARTICLE{schulze-forster_unsupervised_2023,
  author={Schulze-Forster, Kilian and Richard, Gaël and Kelley, Liam and Doire, Clement S. J. and Badeau, Roland},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Unsupervised Music Source Separation Using Differentiable Parametric Source Models}, 
  year={2023},
  volume={31},
  number={},
  pages={1276-1289},
  doi={10.1109/TASLP.2023.3252272}}

@inproceedings{sudholt_vocal_2023,
	title = {Vocal Tract Area Estimation by Gradient Descent},
	author = {S{\"u}dholt, David and Cámara, Mateo and Xu, Zhiyuan and Reiss, Joshua D.},
	year = 2023,
	booktitle = {Proceedings of the 26th {{International Conference}} on {{Digital Audio Effects}}},
	address = {{Copenhagen, Denmark}},
}

@ARTICLE{masuda_improving_2023,
  author={Masuda, Naotake and Saito, Daisuke},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Improving Semi-Supervised Differentiable Synthesizer Sound Matching for Practical Applications}, 
  year={2023},
  volume={31},
  number={},
  pages={863-875},
  doi={10.1109/TASLP.2023.3237161}}
