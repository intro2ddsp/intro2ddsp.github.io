{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additive Synthesis\n",
    "\n",
    "Here we build on our sinusoidal oscillator by summing multiple instances of them together\n",
    "to start to model more complex audio signals. This is known as additive synthesis. We first introduce the most general form\n",
    "of an additive synthesizer, which is unconstrained (i.e. each sinusoidal component can take any frequency or amplitude). After we'll\n",
    "add constraints to this algorithm which adds further inductive bias towards the generation\n",
    "of desired signal components, such as harmonic signals.\n",
    "\n",
    "## Unconstrained Additive Synthesis\n",
    "\n",
    "Motivated by the signal processing interpretation of Fourier's theorem, i.e. that a signal can be decomposed into sinusoidal components, additive synthesis describes a signal as a finite sum of sinusoidal components. Unlike representation in the discrete Fourier basis, however, the frequency axis is not necessarily discretised, allowing for direct specification of component frequencies.\n",
    "The general form for such a model in discrete time is thus:\n",
    "\n",
    "$$\n",
    "    y[n] = \\sum_{k}^{K}\\alpha_k[n]\\sin\\left(\\phi_k + \\sum_{m=0}^{n}\\omega_k[m]\\right)\n",
    "$$\n",
    "\n",
    "where $K$ is the number of sinusoidal components, $\\mathbf{\\alpha}[n]\\in\\mathbb{R}^K$ is a time series of component amplitudes, $\\mathbf{\\phi}\\in\\mathbb{R}^K$ is the component-wise initial phase, and $\\mathbf{\\omega}[n]$ is the time series of instantaneous component frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mplticker\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Random Seed\n",
    "_ = torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_synth(\n",
    "    amplitudes: torch.Tensor,  # Amplitudes\n",
    "    frequencies: torch.Tensor,  # Angular frequencies (rad / sample)\n",
    "):\n",
    "    assert (\n",
    "        frequencies.ndim == 3\n",
    "    ), \"Frequencies must be 3D (batch, n_frequencies, n_samples)\"\n",
    "    assert (\n",
    "        frequencies.shape == amplitudes.shape\n",
    "    ), \"Frequency and amplitude shapes must match\"\n",
    "\n",
    "    # Set initial phase to zero, prepend to frequency envelope\n",
    "    initial_phase = torch.zeros_like(frequencies[:, :, :1])\n",
    "    frequencies = torch.cat([initial_phase, frequencies], dim=-1)\n",
    "\n",
    "    # Create the phase track and remove the last sample (since we added initial phase)\n",
    "    phase = torch.cumsum(frequencies, dim=-1)[..., :-1]\n",
    "    y = torch.sin(phase) * amplitudes\n",
    "    y = torch.sum(y, dim=1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our additive synthesizer\n",
    "\n",
    "Let's create some toy frequency and amplitude envelopes to pass into our additive\n",
    "synthesizer to test it.\n",
    "These could be anything, but let's create envelopes that start from a random frequency,\n",
    "converge to a center frequency, and then diverge back to the random frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 8\n",
    "frequencies = torch.rand(num_components) * 500 + 200\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "target_frequency = 440\n",
    "\n",
    "# Create a frequency envelope that sweeps from the initial frequency to the target frequency\n",
    "frequency_envelopes = []\n",
    "for freq in frequencies:\n",
    "    f_env = torch.linspace(freq, target_frequency, sample_rate).unsqueeze(0)\n",
    "    frequency_envelopes.append(f_env)\n",
    "\n",
    "# Stack all the frequency envelopes together\n",
    "frequency_envelopes = torch.cat(frequency_envelopes, dim=0).unsqueeze(0)\n",
    "\n",
    "# Reverse the frequency envelope and append it to itself - this creates a converging and diverging frequency envelope\n",
    "frequency_envelopes = torch.cat(\n",
    "    [frequency_envelopes, frequency_envelopes.flip(-1)], dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(frequency_envelopes.shape[1]):\n",
    "    plt.plot(frequency_envelopes[0, i])\n",
    "\n",
    "plt.title(\"Additive Synthesizer Frequency Envelopes\")\n",
    "plt.xlabel(\"Time (Samples)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the frequency in Hz to angular frequency, create a static amplitude envelope\n",
    "for each sinusoidal component, and listen to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to rad / sample\n",
    "omegas = 2 * torch.pi * frequency_envelopes / sample_rate\n",
    "\n",
    "# Amplitude envelopes so each frequency has the same amplitude\n",
    "amplitudes = torch.ones(1, omegas.shape[1], omegas.shape[-1])\n",
    "\n",
    "# Synthesize the audio\n",
    "y = additive_synth(amplitudes, omegas)\n",
    "\n",
    "ipd.Audio(y[0].numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained Additive Synthesis\n",
    "\n",
    "Additive synthesis is powerful and in theory can be used to synthesize any sound. However, \n",
    "for some problems we don't need to be able to generate any sound. We can use acoustic knowledge\n",
    "of our target domain to constrain the space of possible solutions. \n",
    "Constraining our synthesizer adds an inductive bias towards the generation of certain classes of sounds.\n",
    "In the context of a machine learning problem, this means that we can potentially solve \n",
    "the problem more efficiently, with smaller models and less data.\n",
    "\n",
    "For instance, many musical instruments are harmonic, meaning\n",
    "that the sinusoidal components are at frequencies that are integer multiples of the fundamental\n",
    "frequency. We can embed this knowledege into our synthesizer to constrain the synthesis\n",
    "space and bias our model towards the generation of harmonic sounds.\n",
    "\n",
    "Harmonically constrained synthesis was used in Engel et al.'s DDSP work and has been the\n",
    "focus of many subsequent DDSP papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harmonic Synthesizer\n",
    "\n",
    "We updated the general form for additive synthesis for harmonic synthesis:\n",
    "\n",
    "$$\n",
    "y[n] = \\sum_{k=1}^{K}\\alpha_k[n]\\sin\\left(\\phi_{k} + k\\sum_{m=0}^{n}\\omega_{0}[m]\\right)\n",
    "$$\n",
    "\n",
    "where $K$ is the number of harmonics, $\\omega_0$ is the time-varying fundamental frequency,\n",
    "and $\\alpha_k$ is the time-varying amplitude for the $k^{\\text{th}}$ harmonic. $\\phi_k$ is\n",
    "the initial phase of the $k^{\\text{th}}$ harmonic, although in practice this is often\n",
    "set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing a harmonic synthesizer\n",
    "\n",
    "To constrain our additive synthesizer we'll first introduce a function that receives\n",
    "a time-varying fundamental frequency envelope and returns a tensor of frequencies\n",
    "with $K$ harmonics that are harmonically related to the fundamental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harmonic_frequencies(f0, num_harmonics):\n",
    "    # Create integer harmonic ratios and reshape to (1, n_harmonics, 1) so we can\n",
    "    # multiply with fundamental frequency tensor repeated for num_harmonics\n",
    "    harmonic_ratios = torch.arange(1, num_harmonics + 1).view(1, -1, 1)\n",
    "\n",
    "    # Duplicate the fundamental frequency for each harmonic\n",
    "    frequencies = f0.unsqueeze(1).repeat(1, num_harmonics, 1)\n",
    "\n",
    "    # Multiply the fundamental frequency by the harmonic ratios\n",
    "    frequencies = frequencies * harmonic_ratios\n",
    "\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a harmonic synthesizer function that receives a fundamental frequency\n",
    "envelope and a set of time-varying amplitudes for $K$ harmonics. Using our function `get_harmonic_frequencies`\n",
    "we'll generate the harmonic frequency envelopes and pass these along with the amplitudes\n",
    "to `additive_synth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_synth(\n",
    "    f0: torch.Tensor,  # Fundamental frequency (Hz) (batch, n_samples)\n",
    "    harmonic_amps: torch.Tensor,  # Amplitudes of harmonics (batch, n_harmonics, n_samples)\n",
    "):\n",
    "    assert f0.ndim == 2, \"Fundamental frequency must be 2D (batch, n_samples)\"\n",
    "    assert (\n",
    "        harmonic_amps.ndim == 3\n",
    "    ), \"Harmonic amplitudes must be 3D (batch, n_harmonics, n_samples)\"\n",
    "\n",
    "    # Create the harmonic frequency envelopes\n",
    "    num_harmonics = harmonic_amps.shape[1]\n",
    "    frequencies = get_harmonic_frequencies(f0, num_harmonics)\n",
    "\n",
    "    return additive_synth(harmonic_amps, frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our harmonic synthesizer\n",
    "\n",
    "Here, we demonstrate our harmonic synthesizer by generating random distributions of\n",
    "harmonics. To turn harmonics into a distribution we'll further constrain the amplitudes\n",
    "of each harmonic to sum to one: $\\sum_{k=0}^{K}c_k = 1$ where $c_k$ is the $k^{\\text{th}}$\n",
    "harmonic amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_harmonic_amps(\n",
    "    batch_size: int,  # Number of samples to generate\n",
    "    num_harmonics: int,  # Number of harmonics to generate\n",
    "    num_samples: int,  # Number of samples in length\n",
    "):\n",
    "    # Create random amplitudes for each harmonic (but set the first harmonic to 1)\n",
    "    harmonic_amps = torch.rand(batch_size, num_harmonics) * 40.0 - 40.0\n",
    "    harmonic_amps = torch.pow(10, harmonic_amps / 20.0)\n",
    "\n",
    "    # Turn harmonic amplitudes into a distribution\n",
    "    harmonic_amps = harmonic_amps / harmonic_amps.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Turn the harmonic amplitudes into a tensor of time-varying amplitudes\n",
    "    harmonic_amps = torch.ones(1, num_harmonics, num_samples) * harmonic_amps.view(\n",
    "        1, -1, 1\n",
    "    )\n",
    "\n",
    "    return harmonic_amps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of creating a static fundamental frequency,\n",
    "let's add some vibrato to this signal. Vibrato is a musical effect where the pitch of note\n",
    "is subtly adjusted in an oscillating way around the main frequency. We can model vibrato\n",
    "by modulating our fundamental frequency with a slow sinusoidal signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 110  # Fundamental frequency (Hz)\n",
    "\n",
    "vibrato_rate = 5.0  # Rate of vibrato (Hz)\n",
    "vibrato_depth = 0.75  # Depth of vibrato (Hz)\n",
    "\n",
    "# Create a sinusoid at the vibrato rate\n",
    "vibrato = torch.ones(1, sample_rate) * vibrato_rate\n",
    "vibrato = 2 * torch.pi * vibrato / sample_rate\n",
    "vibrato = torch.sin(torch.cumsum(vibrato, dim=-1))\n",
    "\n",
    "# Scale the vibrato to the desired depth\n",
    "vibrato_depth = 2 * torch.pi * vibrato_depth / sample_rate\n",
    "vibrato = vibrato * vibrato_depth\n",
    "\n",
    "# Calculate the fundamental frequency in radians / sample\n",
    "fundamental = 2 * torch.pi * f0 / sample_rate\n",
    "\n",
    "# Scale the vibrato to the fundamental frequency\n",
    "fundamental = fundamental + vibrato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at our fundamental frequency envelope, we'll see it slowly oscillating\n",
    "around the fundamental frequency. This is the signal that we then pass into our sinusoidal\n",
    "modelling synthesizer. It's a sinusoidal signal controlling a sinusoidal synthesizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "f0_hz = fundamental * sample_rate / (2 * torch.pi)\n",
    "plt.plot(f0_hz[0])\n",
    "plt.ylim(105, 115)\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.xlabel(\"Time (Samples)\")\n",
    "plt.title(\"Fundamental Frequency with Vibrato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen to our harmonic synthesizer, controlled using our fundamental frequency with\n",
    "added vibrato.\n",
    "\n",
    "To see the effect of different distributions of harmonics, let's create a few different\n",
    "random harmonic distributions and listen to them consecutively.\n",
    "\n",
    "We can also see the different amplitudes of the harmonics in the different sections in the spectrogram below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_harmonics = 16  # Number of harmonics\n",
    "\n",
    "y = []\n",
    "for i in range(8):\n",
    "    harmonic_amps = random_harmonic_amps(1, num_harmonics, sample_rate)\n",
    "    y.append(harmonic_synth(fundamental, harmonic_amps))\n",
    "\n",
    "y = torch.cat(y, dim=1)\n",
    "ipd.Audio(y[0].numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "X = torch.stft(\n",
    "    y,\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    return_complex=True,\n",
    "    window=torch.hann_window(n_fft),\n",
    ")\n",
    "\n",
    "# Convert to decibels\n",
    "X_mag = torch.abs(X)\n",
    "X_db = 20.0 * torch.log10(X_mag + 1e-6)\n",
    "\n",
    "# Get frequencies for each FFT bin in hertz\n",
    "fft_freqs = torch.abs(torch.fft.fftfreq(2048, 1 / sample_rate)[: X_db.shape[1]])\n",
    "\n",
    "# Time in seconds for each frame\n",
    "times = torch.arange(X_db.shape[-1]) * hop_length / sample_rate\n",
    "\n",
    "# Plot the spectrogram\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.pcolormesh(times, fft_freqs, X_db[0].numpy())\n",
    "\n",
    "# Set the y-axis to log scale\n",
    "ax.set_yscale(\"symlog\", base=2.0)\n",
    "ax.set_ylim(20.0, 4000.0)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mplticker.ScalarFormatter())\n",
    "ax.yaxis.set_label_text(\"Frequency (Hz)\")\n",
    "\n",
    "ax.xaxis.set_major_formatter(mplticker.ScalarFormatter())\n",
    "ax.xaxis.set_label_text(\"Time (Seconds)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Constraints\n",
    "\n",
    "Further constraints can be added to a harmonic synthesizer to generate desired signals.\n",
    "\n",
    "Musical synthesizers, such as keyboard synthesizers or modular synths, typically have one or\n",
    "more oscillators with a number of preset waveforms. Sawtooth and square waves are common\n",
    "examples because they are harmonically rich and provide a good starting point for sound\n",
    "shaping using filters. This type of synthesis is referred to a subtractive synthesis and\n",
    "was the method used by popular Moog synthesizers.\n",
    "\n",
    "A sawtooth synthesizer was also used by Wu et al. in SawSing, a differentiable singing voice synthesizer.\n",
    "\n",
    "Here we show how our harmonic synthesizer can be extended to approximate these two popular\n",
    "waveforms. The animations show how adding more harmonics results in a closer approximation\n",
    "to the true waveform shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sawtooth Waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "y_{\\text{saw}}[n] = \\sum_{k=1}^{K}\\frac{2}{\\pi{k}}\\sin\\left(k\\sum_{m=0}^{n}\\omega_0[m]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sawtooth(\n",
    "    num_harmonics: int,  # Number of harmonics to generate\n",
    "    num_samples: int,  # Number of samples in length\n",
    "):\n",
    "    harmonics = torch.arange(1, num_harmonics + 1)\n",
    "    harmonic_amps = 2.0 / (harmonics * torch.pi)\n",
    "\n",
    "    # Turn the harmonic amplitudes into a tensor of time-varying amplitudes\n",
    "    harmonic_amps = torch.ones(1, num_harmonics, num_samples) * harmonic_amps.view(\n",
    "        1, -1, 1\n",
    "    )\n",
    "\n",
    "    return harmonic_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saw_amplitudes = sawtooth(16, sample_rate)\n",
    "y = harmonic_synth(fundamental, saw_amplitudes)\n",
    "ipd.Audio(y[0].numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "(line,) = ax.plot([], [], lw=2)\n",
    "ax.set_ylim([-1.1, 1.1])\n",
    "ax.set_xlim(0, 250)\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    n = i + 1\n",
    "    saw_amplitudes = sawtooth(n, sample_rate)\n",
    "    y = harmonic_synth(fundamental, saw_amplitudes)\n",
    "    line.set_data(torch.arange(250).numpy(), y[0].numpy()[:250])\n",
    "    ax.set_title(f\"Sawtooth Wave with N = {n} Harmonics\")\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "anim = FuncAnimation(fig, animate, init_func=init, frames=24, interval=150, blit=True)\n",
    "plt.close(fig)\n",
    "# To display the animation in the Jupyter notebook:\n",
    "display(ipd.HTML(anim.to_html5_video()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square wave\n",
    "\n",
    "$$\n",
    "y_{\\text{square}}[n] = \\sum_{k=1}^{K}\\frac{4}{\\pi(2k -1)}\\sin\\left(2\\pi(2k - 1)\\sum_{m=0}^{n}\\omega_0[m]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_wave(\n",
    "    num_harmonics: int,  # Number of harmonics to generate\n",
    "    num_samples: int,  # Number of samples in length\n",
    "):\n",
    "    harmonic_amps = torch.zeros(num_harmonics * 2)\n",
    "    for i in range(1, len(harmonic_amps) + 1):\n",
    "        if (i - 1) % 2 == 0:\n",
    "            harmonic_amps[i - 1] = 4.0 / (torch.pi * i)\n",
    "\n",
    "    # Turn the harmonic amplitudes into a tensor of time-varying amplitudes\n",
    "    harmonic_amps = torch.ones(1, num_harmonics * 2, num_samples) * harmonic_amps.view(\n",
    "        1, -1, 1\n",
    "    )\n",
    "\n",
    "    return harmonic_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_amplitudes = square_wave(16, sample_rate)\n",
    "y = harmonic_synth(fundamental, square_amplitudes)\n",
    "ipd.Audio(y[0].numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "(line,) = ax.plot([], [], lw=2)\n",
    "\n",
    "max_amp = square_amplitudes.abs().max()\n",
    "ax.set_ylim([-max_amp, max_amp])\n",
    "ax.set_xlim(0, 250)\n",
    "ax.grid(True)\n",
    "\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    n = i + 1\n",
    "    square_amplitudes = square_wave(n, sample_rate)\n",
    "    y = harmonic_synth(fundamental, square_amplitudes)\n",
    "    line.set_data(torch.arange(250).numpy(), y[0].numpy()[:250])\n",
    "    ax.set_title(f\"Square Wave with N = {n} Harmonics\")\n",
    "    return (line,)\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "anim = FuncAnimation(fig, animate, init_func=init, frames=24, interval=200, blit=True)\n",
    "plt.close(fig)\n",
    "# To display the animation in the Jupyter notebook:\n",
    "display(ipd.HTML(anim.to_html5_video()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ismir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
